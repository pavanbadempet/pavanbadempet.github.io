# Sections content configuration file
### use navigation.yml file to re-order, delete or add section of each card
### here you can find all content in all pre-build sections

### About [ about ]
about:
  image: "assets/img/pavan_badempet.png"
  image_alt: "Pavan Badempet - Data Engineer"
  text: "<p><b>Data Engineer</b> with 2+ years of experience building scalable ETL/ELT pipelines using Python, SQL, and Spark across AWS and on-prem environments. Solid grounding in computer science fundamentals, including data structures and algorithms, and distributed systems, applied to batch processing, data quality, and fault-tolerant pipeline design. Experience working on large-scale Spark ETL systems for FinTech and Automotive domains, with a focus on performance optimization and reliability.</p>"

  list:

    - label: "Address"
      value: "Hyderabad, TS"

    - label: "Phone"
      value: "<a href='tel:+917989256101'>+91 7989256101</a>"

    - label: "E-mail"
      value: "<a href='mailto:pavan9b@gmail.com'>pavan9b@gmail.com</a>"
    
    - label: "LinkedIn"
      value: "<a href='https://linkedin.com/in/pavanbadempet/'>pavanbadempet</a>"

    - label: "GitHub"
      value: "<a href='https://github.com/pavanbadempet'>pavanbadempet</a>"

  download:
    text: "Download Resume"
    link: "https://drive.google.com/file/d/1gppjKAn5s9W06uH4ajoj7Ha2H13zEPkq/view?usp=sharing"

### Resume [ resume ]
resume:
  experience:
    title: "Experience"
    items:
      - year: "Nov 2023 – Present"
        name: "Data Engineer - Tata Consultancy Services"
        text1: "<b>Nomura Capital:</b> Engineered and maintained large-scale Spark ETL pipelines using Spark SQL and complex analytical SQL queries for capital markets datasets (trades, reference, risk, and valuation feeds), involving multi-way joins and window functions to support downstream reporting and risk analytics."
        text2: "Analyzed Spark execution metrics to improve execution time by 30% through broadcast joins, partition pruning, predicate pushdown, and optimized star schema joins between fact and dimension tables."
        text3: "Orchestrated Spark workflows using AutoSys, managing dependency chains, reruns, and recovery logic, improving batch completion reliability and reducing manual intervention by 25%."
        text4: "Executed migration of Spark workloads from YARN to Kubernetes, transitioning storage from HDFS to MinIO (S3-compatible), resolving Spark connector and storage compatibility issues."
        text5: "<b>Nissan:</b> Architected daily batch pipelines using AWS Lambda and Step Functions, while developing a Streamlit interface for ad-hoc file ingestion and idempotent re-runs for business users."
        text6: "Implemented schema validation, data quality checks, and incremental batch processing with idempotent re-runs, preparing curated datasets for Snowflake Data Warehouse ingestion and reducing manual effort by 60%."
        text7: "Improved pipeline reliability via retries, implementing comprehensive monitoring and alerting using CloudWatch with automated notifications for pipeline failures, data freshness, and quality issues, reducing MTTR by 30%."

      - year: "Mar 2023 – Apr 2023"
        name: "Data Analytics Intern - TCS iON"
        text1: "Implemented an ensemble-based attrition prediction model, achieving 86% accuracy on validation data."
        text2: "Designed a lightweight FastAPI service to expose the model for real-time inference and testing."

  education:
    title: "Education"
    items:
      - year: "Aug 2019 – Sep 2023"
        college: "<b>College:</b> Guru Nanak Institutions Technical Campus"
        degree: "<b>Degree:</b> Bachelor of Technology in Computer Science & Engineering"
        major: "<b>Minor:</b> AI/ML"
        macgpa: "<b>Grade:</b> 8.2 CGPA (First Class with Distinction)"
        macoursework: "<b>Scholarships:</b> Prime Minister’s Scholarship 2019-2023"

### Skills [ skills ]
skills:
  columns:
    - type: "list"
      title: "Programming Languages"
      items:
        - label: "Python"
        - label: "SQL"
        - label: "Scala"
        - label: "Java"

    - type: "list"
      title: "Data Processing"
      items:
        - label: "Apache Spark (PySpark, Spark SQL)"
        - label: "Pandas"
        - label: "NumPy"

    - type: "list"
      title: "Cloud & Storage"
      items:
        - label: "AWS (Lambda, Glue, Step Functions, S3)"
        - label: "Snowflake"
        - label: "MinIO"

    - type: "list"
      title: "Tools"
      items:
        - label: "AutoSys"
        - label: "Docker"
        - label: "Git"
        - label: "FastAPI"
        - label: "Streamlit"
        - label: "Pytest"

### Projects [ team ]
team:
  title: "Projects"
  items:
    - name: AI Healthcare System
      role: "Python, Pandas, FastAPI, Streamlit, Render, Neon, GCP, Docker"
      text1: "Built automated ETL pipelines processing 250k+ records to train XGBoost classifiers; implemented comprehensive data quality checks achieving 89% prediction accuracy."
      text2: "Architected a decoupled application with FastAPI backend and Streamlit frontend, containerized via Docker for deployment on GCP/Render, with managed PostgreSQL database on Neon."
      text3: "Integrated a RAG using Gemini to provide context-aware queries, significantly reducing manual data entry."

    - name: "Movie Recommendation System"
      role: "Python, PySpark, FastAPI, Streamlit, Render, Azure"
      text1: "Built end-to-end recommendation pipeline processing 1M+ movie records using PySpark for ETL and Cosine Similarity for efficient similarity search."
      text2: "Deployed model via FastAPI backend and Streamlit UI, enabling real-time content-based filtering."
      text3: ""

### Honors & Awards [ clients ]
clients:
  title: "Honors & Awards"
  items:
    - image: ""
      name: "Prime Minister's Scholarship Scheme"
      role: "Awarded for academic excellence during studies as part of the Prime Minister's Scholarship Scheme."
  

### Contact Info [ contacts-info ]
contacts_info:
  title: "Contact Info"
  list:
    - label: "Phone"
      icon: "fas fa-phone"
      value: "<a href='tel:+917989256101'>+91 7989256101</a>"

    - label: "Email"
      icon:  "fas fa-envelope"
      value: "<a href='mailto:pavan9b@gmail.com'>pavan9b@gmail.com</a>"

    - label: "Address"
      icon: "fas fa-map-marker-alt"
      value: "Hyderabad, TS"
    
    - label: "Open to"
      icon: "fas fa-user-tie"
      value: "I am open to opportunities for full-time positions, contract work, and freelance engagements."

### Services [ services ]
services:
  title: "What I Do"
  items:
    - name: "Data Pipeline Architecture"
      text: "Designing and implementing scalable ETL/ELT workflows using Apache Spark, AWS Glue, and Lambda to process terabytes of data efficiently."
      icon: "fas fa-network-wired"

    - name: "Cloud Data Platforms"
      text: "Designing secure, serverless data lakes and warehouses on AWS (S3, Redshift, Athena) and Azure, ensuring high availability and cost optimization."
      icon: "fas fa-cloud"

    - name: "Big Data Processing"
      text: "Optimizing complex SQL queries and Spark jobs for finding patterns in massive datasets, reducing processing time and improving data quality."
      icon: "fas fa-database"

    - name: "MLOps & AI Integration"
      text: "Deploying machine learning models and GenAI agents into production environments using Docker, FastAPI, and CI/CD pipelines."
      icon: "fas fa-robot"